# AI-Virtual-mouse
It is an ai python open cv project.We can use all the mouse movements by hand gusture

![0_OfoZ60WfklcJji7O](https://github.com/user-attachments/assets/4efbfe37-57c4-46e2-b1bb-bbfce242945a)

ğŸ§  Description:

This project implements an AI-powered virtual mouse using Python, OpenCV, and hand gesture recognition. The system uses a webcam to track hand landmarks and interprets specific gestures to control the mouse and system functions, offering a touchless and futuristic way to interact with your computer.

ğŸ’¡ Key Features:

ğŸ–±ï¸ Mouse Control via Hand Gestures:

Left Click: Tap gesture using index and thumb fingers

Right Click: Gesture with index and middle fingers together

Double Click: touching both index and middle fingers

Mouse Movement: Move cursor by moving the index and middle finger in real time

Drag and drop: Holding all fingers

ğŸ”„ Scroll Control:

Vertical scrolling using finger movement (e.g., index and  thumb apart or closed)

ğŸ”Š System Control:

Volume Control: Adjust volume with index and thumb finger touched and move in horizontal direction

Brightness Control: Adjust screen brightness with index and thumb finger touched and move in horizontal direction
![imag 1_41750](https://github.com/user-attachments/assets/3f8e6eb2-5b8f-42d3-98cb-bc53e89a87d3)


ğŸ› ï¸ Technologies Used:

Python

OpenCV

MediaPipe (for hand tracking)

PyAutoGUI (for controlling the mouse)

Numpy

Pycaw / ScreenBright (for volume and brightness control)

ğŸš€ Highlights:

Real-time hand gesture tracking with high accuracy

Fully contactless and intuitive user interface

Compatible with most webcams and platforms

Useful for accessibility, presentations, and smart automation

ğŸ”š Conclusion:

This AI Virtual Mouse project is a powerful demonstration of computer vision and human-computer interaction. It replaces traditional input devices with hand gestures, pushing the boundaries of contactless control and accessibility in computing.
